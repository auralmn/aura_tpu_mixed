import asyncio
import json
import numpy as np
from typing import List, Dict, Any, Tuple, Set
from datetime import datetime
from collections import defaultdict, deque
import networkx as nx

class AuraCausalHistoryTrainer:
    def __init__(self, aura_network, network_mapper=None):
        self.aura = aura_network
        self.mapper = network_mapper
        
        # Causal intelligence statistics
        self.causal_stats = {
            'total_events_processed': 0,
            'causal_links_learned': 0,
            'butterfly_effects_analyzed': 0,
            'similarity_networks_built': 0,
            'downstream_chains_discovered': 0,
            'counterfactual_scenarios_processed': 0,
            'temporal_causal_patterns': defaultdict(list),
            'influence_factor_distribution': defaultdict(float),
            'event_type_causality_matrix': defaultdict(lambda: defaultdict(float)),
            'butterfly_index_distribution': [],
            'multi_hop_influence_paths': [],
            'sentiment_causality_correlations': [],
            'geographic_influence_patterns': defaultdict(list)
        }
        
        # Causal reasoning networks
        self.causal_graph = nx.DiGraph()  # Directed graph for causal relationships
        self.similarity_graph = nx.Graph()  # Undirected graph for similar events
        self.butterfly_scenarios = []  # Store counterfactual scenarios
        self.temporal_clusters = defaultdict(list)  # Events clustered by time periods
        
        # Advanced pattern recognition
        self.causal_patterns = {
            'innovation_chains': [],  # Technology -> adoption -> transformation
            'cultural_influence_paths': [],  # Art -> movement -> society change
            'social_cascades': [],  # Individual -> community -> society
            'crisis_responses': [],  # Problem -> solution -> consequences
            'evolutionary_progressions': []  # Incremental improvements
        }
        
    async def process_causal_history_dataset(self, dataset_path: str):
        """Process rich causal history dataset through Aura's intelligence"""
        
        print(f"üåä Starting Aura causal history training: {dataset_path}")
        
        # Load causal events
        causal_events = self._load_causal_events(dataset_path)
        
        # Sort chronologically for temporal learning
        sorted_events = sorted(causal_events, key=lambda x: x.get('earliest_date_year', 0))
        
        # Phase 1: Process individual events
        await self._process_individual_events(sorted_events)
        
        # Phase 2: Build causal networks
        await self._build_causal_networks(sorted_events)
        
        # Phase 3: Analyze butterfly effects and counterfactuals
        await self._analyze_butterfly_effects(sorted_events)
        
        # Phase 4: Discover advanced causal patterns
        await self._discover_causal_patterns(sorted_events)
        
        # Phase 5: Train neural networks on causal reasoning
        await self._train_causal_reasoning_networks()
        
        # Generate comprehensive report
        await self._generate_causal_training_report()
        
        print(f"üß† Causal intelligence training complete!")
    
    def _load_causal_events(self, dataset_path: str) -> List[Dict]:
        """Load causal events dataset"""
        
        events = []
        
        with open(dataset_path, 'r') as f:
            for line in f:
                try:
                    event = json.loads(line.strip())
                    events.append(event)
                except json.JSONDecodeError:
                    continue
        
        print(f"üåä Loaded {len(events)} causal events")
        return events
    
    async def _process_individual_events(self, events: List[Dict]):
        """Process individual events through neural pipeline"""
        
        print("üîç Processing individual events...")
        
        batch_size = 15  # Smaller batches for complex processing
        
        for i in range(0, len(events), batch_size):
            batch = events[i:i+batch_size]
            
            print(f"üìä Processing causal batch {i//batch_size + 1}/{(len(events)-1)//batch_size + 1}")
            
            for event in batch:
                await self._process_causal_event(event)
            
            # Update visualization every batch
            if self.mapper:
                await self.mapper.update_network_map(
                    self.aura,
                    current_query=f"Causal learning: {batch[0].get('title', 'Event')[:50]}...",
                    query_features=self._generate_causal_context_features()
                )
            
            await asyncio.sleep(0.1)
    
    async def _process_causal_event(self, event: Dict):
        """Process single causal event through Aura's systems"""
        
        # Extract core event information
        title = event.get('title', 'Unknown Event')
        summary = event.get('summary', '')
        source_text = event.get('source_text', '')
        event_type = event.get('event_type', 'general')
        
        # Update statistics
        self.causal_stats['total_events_processed'] += 1
        
        # Extract rich causal features
        causal_features = self._extract_causal_features(event)
        
        # Generate semantic representation
        full_text = f"{title} {summary} {source_text}"
        event_features = self.aura.sbert.encode(full_text)
        
        # Process through neural pipeline with causal context
        await self._process_through_causal_neural_pipeline(event, event_features, causal_features)
        
        # Add to causal graph
        self._add_event_to_causal_graph(event, causal_features)
    
    def _extract_causal_features(self, event: Dict) -> Dict:
        """Extract sophisticated causal features from event"""
        
        features = {
            'butterfly_index': event.get('butterfly_index', 0.0),
            'energy': event.get('energy', 0.5),
            'sentiment_score': event.get('sentiment_score', 0.5),
            'pleasantness': event.get('pleasantness', 0.5),
            'causal_effect_score': 0.0,
            'influence_factor_scores': {},
            'downstream_influence_strength': 0.0,
            'precursor_complexity': 0.0,
            'similarity_connectivity': 0.0,
            'temporal_significance': 0.0
        }
        
        # Extract causal link information
        causal_link = event.get('causal_link', {})
        if causal_link:
            features['causal_effect_score'] = causal_link.get('effect_score', 0.0)
            
            # Process influence factors
            influence_factors = causal_link.get('influence_factors', [])
            for factor in influence_factors:
                factor_name = factor.get('factor', 'Unknown')
                factor_score = factor.get('score', 0.0)
                features['influence_factor_scores'][factor_name] = factor_score
        
        # Calculate downstream influence strength
        downstream = event.get('downstream_influence', [])
        if downstream:
            # Weighted average of cumulative influences
            influences = [d.get('cumulative_influence', 0.0) for d in downstream]
            features['downstream_influence_strength'] = np.mean(influences) if influences else 0.0
        
        # Calculate precursor complexity
        precursors = event.get('precursor_events', [])
        features['precursor_complexity'] = len(precursors) / 10.0  # Normalize
        
        # Calculate similarity connectivity
        similar_events = event.get('similar_events', [])
        if similar_events:
            sim_scores = [s.get('similarity_score', 0.0) for s in similar_events]
            features['similarity_connectivity'] = np.mean(sim_scores)
        
        # Calculate temporal significance
        date_span = event.get('date_span_years', 0)
        earliest_year = event.get('earliest_date_year', 0)
        
        # More recent events and longer-spanning events have higher temporal significance
        current_year = 2025
        years_ago = max(1, current_year - earliest_year)
        features['temporal_significance'] = (1.0 / np.log(years_ago + 1)) + (date_span / 100.0)
        
        return features
    
    async def _process_through_causal_neural_pipeline(self, event: Dict, 
                                                   event_features: np.ndarray, 
                                                   causal_features: Dict):
        """Process event through causal reasoning pipeline"""
        
        # 1. CNS Assessment with causal focus
        global_state = self.aura._cns.assess_global_state()
        
        # 2. Enhanced context for causal learning
        causal_context = {
            'type': 'causal_historical_analysis',
            'urgency': 0.4,  # Historical analysis requires focus but not urgency
            'complexity': self._assess_causal_complexity(event, causal_features),
            'causal_significance': causal_features['causal_effect_score'],
            'butterfly_potential': causal_features['butterfly_index'],
            'temporal_importance': causal_features['temporal_significance'],
            'influence_network_position': causal_features['downstream_influence_strength']
        }
        
        # 3. Thalamic routing for causal analysis
        routing_decision = self.aura._thalamic_router.analyze_conversation_intent(
            event.get('title', ''), event_features
        )
        
        # Causal analysis should engage historical, analytical, and hippocampus
        expected_routing = ['historical_specialist', 'analytical_specialist', 'hippocampus_specialist']
        routing_accuracy = self._evaluate_causal_routing(routing_decision, expected_routing)
        
        # 4. Hippocampal causal memory formation
        if hasattr(self.aura, '_hippocampus'):
            await self._encode_causal_memory(event, event_features, causal_features)
        
        # 5. Amygdala processing for significance and impact
        if hasattr(self.aura, '_amygdala'):
            await self._process_causal_significance(event, event_features, causal_features)
        
        # 6. Learn causal reasoning patterns
        await self._learn_causal_patterns(event, event_features, causal_features, routing_accuracy)
    
    def _assess_causal_complexity(self, event: Dict, causal_features: Dict) -> float:
        """Assess complexity of causal relationships"""
        
        complexity_factors = []
        
        # Number of influence factors
        influence_count = len(causal_features['influence_factor_scores'])
        complexity_factors.append(min(1.0, influence_count / 5.0))
        
        # Downstream influence complexity
        downstream = event.get('downstream_influence', [])
        max_hop_distance = max([d.get('hop_distance', 0) for d in downstream], default=0)
        complexity_factors.append(min(1.0, max_hop_distance / 5.0))
        
        # Precursor complexity
        complexity_factors.append(causal_features['precursor_complexity'])
        
        # Butterfly effect complexity
        butterfly_analysis = event.get('butterfly_effect_analysis', {})
        if butterfly_analysis:
            complexity_factors.append(0.8)  # Butterfly effects add complexity
        else:
            complexity_factors.append(0.3)
        
        # Similar events connectivity
        complexity_factors.append(causal_features['similarity_connectivity'])
        
        return np.mean(complexity_factors)
    
    def _evaluate_causal_routing(self, routing_decision: Dict, expected: List[str]) -> float:
        """Evaluate routing accuracy for causal analysis"""
        
        primary_target = routing_decision.get('primary_target', '')
        secondary_targets = routing_decision.get('secondary_targets', [])
        all_targets = [primary_target] + secondary_targets
        
        # Causal analysis needs historical context and analytical reasoning
        relevant_matches = sum(1 for target in all_targets 
                             if any(keyword in target for keyword in ['historical', 'analytical', 'hippocampus']))
        
        total_targets = len(all_targets) if all_targets else 1
        return min(1.0, relevant_matches / total_targets)
    
    async def _encode_causal_memory(self, event: Dict, features: np.ndarray, causal_features: Dict):
        """Encode causal relationships in hippocampal memory"""
        
        if hasattr(self.aura, '_hippocampus'):
            # Create enhanced feature vector for causal memory
            causal_enhanced_features = np.concatenate([
                features[:300],  # Original semantic features
                [causal_features['causal_effect_score']],
                [causal_features['butterfly_index']],
                [causal_features['downstream_influence_strength']],
                [causal_features['temporal_significance']]
            ])
            
            # Encode with temporal context
            memory_trace = self.aura._hippocampus.encode_memory(
                causal_enhanced_features, 
                event.get('earliest_date_year', 0)
            )
            
            # Stimulate neurogenesis for high-impact causal events
            if causal_features['causal_effect_score'] > 0.7 or causal_features['butterfly_index'] > 0.6:
                new_neurons = self.aura._hippocampus.stimulate_neurogenesis()
                self.causal_stats['causal_links_learned'] += len(new_neurons)
    
    async def _process_causal_significance(self, event: Dict, features: np.ndarray, causal_features: Dict):
        """Process causal significance through amygdala"""
        
        if hasattr(self.aura, '_amygdala'):
            # Assess emotional/significance response to causal impact
            significance_context = {
                'butterfly_potential': causal_features['butterfly_index'],
                'historical_impact': causal_features['downstream_influence_strength'],
                'emotional_valence': event.get('sentiment_score', 0.5)
            }
            
            significance_response = self.aura._amygdala.process_emotional_salience(
                features, significance_context
            )
            
            # High-impact causal events get strong emotional encoding
            if causal_features['causal_effect_score'] > 0.8:
                await self.aura._amygdala.fear_conditioning(features, 'significant', event)
    
    async def _learn_causal_patterns(self, event: Dict, features: np.ndarray, 
                                   causal_features: Dict, routing_accuracy: float):
        """Learn causal reasoning patterns"""
        
        # 1. Update causal reasoning neurons
        await self._update_causal_reasoning_neurons(features, causal_features)
        
        # 2. Update temporal sequence understanding
        await self._update_temporal_causal_learning(event, features, causal_features)
        
        # 3. Update butterfly effect understanding
        await self._update_butterfly_effect_learning(event, features, causal_features)
        
        # 4. Update influence factor recognition
        await self._update_influence_factor_learning(event, features, causal_features)
    
    async def _update_causal_reasoning_neurons(self, features: np.ndarray, causal_features: Dict):
        """Update neurons responsible for causal reasoning"""
        
        # Target causal effect score as learning target
        causal_target = causal_features['causal_effect_score']
        
        # Update analytical specialist neurons for causal reasoning
        if hasattr(self.aura, '_conversational_cortex'):
            for neuron in self.aura._conversational_cortex.analytical_neurons[:5]:
                try:
                    await neuron.update_nlms(features, causal_target)
                except:
                    pass
    
    async def _update_temporal_causal_learning(self, event: Dict, features: np.ndarray, causal_features: Dict):
        """Update understanding of temporal causal sequences"""
        
        # Use temporal significance as learning signal
        temporal_target = causal_features['temporal_significance']
        
        # Update hippocampal neurons for temporal-causal patterns
        if hasattr(self.aura, '_hippocampus'):
            for neuron in self.aura._hippocampus.neurons[:5]:
                try:
                    await neuron.update_nlms(features, temporal_target)
                except:
                    pass
    
    async def _update_butterfly_effect_learning(self, event: Dict, features: np.ndarray, causal_features: Dict):
        """Update understanding of butterfly effects and counterfactuals"""
        
        butterfly_target = causal_features['butterfly_index']
        
        # Update neurons that handle complex, non-linear thinking
        if hasattr(self.aura, '_conversational_cortex'):
            for neuron in self.aura._conversational_cortex.comprehension_neurons[:3]:
                try:
                    await neuron.update_nlms(features, butterfly_target)
                except:
                    pass
    
    async def _update_influence_factor_learning(self, event: Dict, features: np.ndarray, causal_features: Dict):
        """Update recognition of different influence factors"""
        
        # Use average influence factor score as target
        influence_scores = list(causal_features['influence_factor_scores'].values())
        if influence_scores:
            influence_target = np.mean(influence_scores)
            
            # Update routing neurons for better factor recognition
            if hasattr(self.aura, '_thalamic_router'):
                router = self.aura._thalamic_router
                if 'analytical_specialist' in router.routing_neurons:
                    for neuron in router.routing_neurons['analytical_specialist'][:3]:
                        try:
                            await neuron.update_nlms(features, influence_target)
                        except:
                            pass
    
    def _add_event_to_causal_graph(self, event: Dict, causal_features: Dict):
        """Add event to causal relationship graph"""
        
        event_id = event.get('event_id', f"event_{self.causal_stats['total_events_processed']}")
        
        # Add node to causal graph
        self.causal_graph.add_node(event_id, 
                                  title=event.get('title', 'Unknown'),
                                  year=event.get('earliest_date_year', 0),
                                  event_type=event.get('event_type', 'general'),
                                  causal_features=causal_features)
        
        # Add to similarity graph with similar events
        similar_events = event.get('similar_events', [])
        for similar in similar_events:
            similarity_score = similar.get('similarity_score', 0.0)
            if similarity_score > 0.7:  # Only strong similarities
                similar_id = f"similar_{hash(similar.get('event_summary', ''))}"
                self.similarity_graph.add_edge(event_id, similar_id, 
                                             weight=similarity_score,
                                             reasoning=similar.get('reasoning', ''))
    
    async def _build_causal_networks(self, events: List[Dict]):
        """Build comprehensive causal networks"""
        
        print("üï∏Ô∏è Building causal networks...")
        
        for event in events:
            event_id = event.get('event_id', f"event_{events.index(event)}")
            
            # Add downstream causal links
            downstream = event.get('downstream_influence', [])
            for influence in downstream:
                next_event_summary = influence.get('event_summary', '')
                cumulative_influence = influence.get('cumulative_influence', 0.0)
                hop_distance = influence.get('hop_distance', 1)
                
                next_event_id = f"downstream_{hash(next_event_summary)}"
                
                if cumulative_influence > 0.3:  # Only significant influences
                    self.causal_graph.add_edge(event_id, next_event_id,
                                             influence_strength=cumulative_influence,
                                             hop_distance=hop_distance,
                                             relationship_type='downstream')
            
            # Add precursor links
            precursors = event.get('precursor_events', [])
            for precursor in precursors:
                precursor_desc = precursor.get('description', '')
                precursor_year = precursor.get('year_parsed', 0)
                
                precursor_id = f"precursor_{hash(precursor_desc)}"
                
                self.causal_graph.add_edge(precursor_id, event_id,
                                         relationship_type='precursor',
                                         temporal_gap=event.get('earliest_date_year', 0) - precursor_year)
        
        print(f"üîó Built causal graph with {self.causal_graph.number_of_nodes()} nodes and {self.causal_graph.number_of_edges()} edges")
    
    async def _analyze_butterfly_effects(self, events: List[Dict]):
        """Analyze butterfly effects and counterfactual scenarios"""
        
        print("ü¶ã Analyzing butterfly effects...")
        
        for event in events:
            butterfly_analysis = event.get('butterfly_effect_analysis', {})
            
            if butterfly_analysis:
                butterfly_scenario = {
                    'event_id': event.get('event_id', ''),
                    'micro_event': butterfly_analysis.get('micro_event_description', ''),
                    'macro_consequence': butterfly_analysis.get('potential_macro_event', ''),
                    'probability': butterfly_analysis.get('probability_score', 0.0),
                    'causal_reasoning': butterfly_analysis.get('causal_chain_reasoning', ''),
                    'butterfly_index': event.get('butterfly_index', 0.0)
                }
                
                self.butterfly_scenarios.append(butterfly_scenario)
                self.causal_stats['butterfly_effects_analyzed'] += 1
                self.causal_stats['butterfly_index_distribution'].append(butterfly_scenario['butterfly_index'])
        
        print(f"ü¶ã Analyzed {len(self.butterfly_scenarios)} butterfly effect scenarios")
    
    async def _discover_causal_patterns(self, events: List[Dict]):
        """Discover advanced causal patterns across events"""
        
        print("üîç Discovering causal patterns...")
        
        # Group events by type for pattern analysis
        events_by_type = defaultdict(list)
        for event in events:
            event_type = event.get('event_type', 'general')
            events_by_type[event_type].append(event)
        
        # Discover innovation chains
        await self._discover_innovation_chains(events_by_type.get('science_technology', []))
        
        # Discover cultural influence paths
        await self._discover_cultural_influence_paths(events_by_type.get('art_culture', []))
        
        # Discover cross-type causal relationships
        await self._discover_cross_type_causality(events_by_type)
        
        # Analyze temporal clustering patterns
        await self._analyze_temporal_clustering(events)
    
    async def _discover_innovation_chains(self, tech_events: List[Dict]):
        """Discover innovation chains in technological events"""
        
        # Sort by date
        sorted_tech = sorted(tech_events, key=lambda x: x.get('earliest_date_year', 0))
        
        chains = []
        current_chain = []
        
        for i, event in enumerate(sorted_tech):
            if i == 0:
                current_chain = [event]
                continue
            
            # Check if this event builds on previous ones
            downstream = event.get('downstream_influence', [])
            precursors = event.get('precursor_events', [])
            
            # Look for connections to previous event in current chain
            if current_chain:
                last_event = current_chain[-1]
                
                # Check for strong causal connection
                connection_strength = 0.0
                for influence in last_event.get('downstream_influence', []):
                    if self._events_similar(influence.get('event_summary', ''), event.get('summary', '')):
                        connection_strength = influence.get('cumulative_influence', 0.0)
                        break
                
                if connection_strength > 0.5:
                    current_chain.append(event)
                else:
                    # End current chain, start new one
                    if len(current_chain) > 1:
                        chains.append(current_chain)
                    current_chain = [event]
        
        # Add final chain
        if len(current_chain) > 1:
            chains.append(current_chain)
        
        self.causal_patterns['innovation_chains'] = chains
        print(f"‚öôÔ∏è Discovered {len(chains)} innovation chains")
    
    async def _discover_cultural_influence_paths(self, cultural_events: List[Dict]):
        """Discover cultural influence pathways"""
        
        # Similar to innovation chains but for cultural events
        sorted_cultural = sorted(cultural_events, key=lambda x: x.get('earliest_date_year', 0))
        
        influence_paths = []
        
        for event in sorted_cultural:
            path = {
                'origin_event': event.get('title', ''),
                'downstream_influences': [],
                'cultural_impact_score': event.get('causal_link', {}).get('effect_score', 0.0),
                'temporal_span': 0
            }
            
            # Trace downstream cultural influences
            for influence in event.get('downstream_influence', []):
                if influence.get('cumulative_influence', 0.0) > 0.4:
                    path['downstream_influences'].append(influence)
                    path['temporal_span'] = max(path['temporal_span'], 
                                              influence.get('hop_distance', 0) * 20)  # Approximate years
            
            if path['downstream_influences']:
                influence_paths.append(path)
        
        self.causal_patterns['cultural_influence_paths'] = influence_paths
        print(f"üé® Discovered {len(influence_paths)} cultural influence paths")
    
    async def _discover_cross_type_causality(self, events_by_type: Dict[str, List[Dict]]):
        """Discover causal relationships across different event types"""
        
        cross_type_links = []
        
        for type1, events1 in events_by_type.items():
            for type2, events2 in events_by_type.items():
                if type1 != type2:
                    # Look for cross-type influences
                    for event1 in events1:
                        for event2 in events2:
                            # Check if event1 influences event2
                            influence_strength = self._calculate_cross_event_influence(event1, event2)
                            
                            if influence_strength > 0.5:
                                cross_type_links.append({
                                    'source_event': event1.get('title', ''),
                                    'source_type': type1,
                                    'target_event': event2.get('title', ''),
                                    'target_type': type2,
                                    'influence_strength': influence_strength,
                                    'temporal_gap': abs(event2.get('earliest_date_year', 0) - 
                                                      event1.get('earliest_date_year', 0))
                                })
        
        # Store in event type causality matrix
        for link in cross_type_links:
            self.causal_stats['event_type_causality_matrix'][link['source_type']][link['target_type']] += link['influence_strength']
        
        print(f"üîó Discovered {len(cross_type_links)} cross-type causal relationships")
    
    async def _analyze_temporal_clustering(self, events: List[Dict]):
        """Analyze temporal clustering patterns"""
        
        # Group events by century/era
        for event in events:
            year = event.get('earliest_date_year', 0)
            century = (year // 100) * 100  # Round to century
            
            self.temporal_clusters[century].append(event)
        
        # Analyze patterns within each cluster
        for century, cluster_events in self.temporal_clusters.items():
            if len(cluster_events) > 3:  # Only analyze substantial clusters
                cluster_analysis = {
                    'century': century,
                    'event_count': len(cluster_events),
                    'dominant_types': self._get_dominant_event_types(cluster_events),
                    'average_butterfly_index': np.mean([e.get('butterfly_index', 0.0) for e in cluster_events]),
                    'causal_density': self._calculate_causal_density(cluster_events)
                }
                
                self.causal_stats['temporal_causal_patterns'][century].append(cluster_analysis)
    
    def _events_similar(self, text1: str, text2: str, threshold: float = 0.6) -> bool:
        """Check if two event descriptions are similar"""
        
        # Simple similarity check based on common words
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return False
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        jaccard_similarity = intersection / union if union > 0 else 0.0
        
        return jaccard_similarity >= threshold
    
    def _calculate_cross_event_influence(self, event1: Dict, event2: Dict) -> float:
        """Calculate influence strength between two events"""
        
        # Check if event2 is mentioned in event1's downstream influences
        for influence in event1.get('downstream_influence', []):
            if self._events_similar(influence.get('event_summary', ''), event2.get('summary', '')):
                return influence.get('cumulative_influence', 0.0)
        
        # Check if events are similar (indirect influence)
        for similar in event1.get('similar_events', []):
            if self._events_similar(similar.get('event_summary', ''), event2.get('summary', '')):
                return similar.get('similarity_score', 0.0) * 0.7  # Discount for indirect
        
        return 0.0
    
    def _get_dominant_event_types(self, events: List[Dict]) -> List[str]:
        """Get most common event types in a cluster"""
        
        type_counts = defaultdict(int)
        for event in events:
            event_type = event.get('event_type', 'general')
            type_counts[event_type] += 1
        
        # Return top 3 types
        sorted_types = sorted(type_counts.items(), key=lambda x: x[1], reverse=True)
        return [t[0] for t in sorted_types[:3]]
    
    def _calculate_causal_density(self, events: List[Dict]) -> float:
        """Calculate causal relationship density within event cluster"""
        
        if len(events) < 2:
            return 0.0
        
        total_possible_links = len(events) * (len(events) - 1)  # Directed graph
        actual_links = 0
        
        for event1 in events:
            for event2 in events:
                if event1 != event2:
                    influence = self._calculate_cross_event_influence(event1, event2)
                    if influence > 0.3:
                        actual_links += 1
        
        return actual_links / total_possible_links if total_possible_links > 0 else 0.0
    
    async def _train_causal_reasoning_networks(self):
        """Train neural networks on discovered causal patterns"""
        
        print("üß† Training causal reasoning networks...")
        
        # Create training data from causal patterns
        training_examples = []
        
        # Use innovation chains as training examples
        for chain in self.causal_patterns['innovation_chains']:
            for i in range(len(chain) - 1):
                source_event = chain[i]
                target_event = chain[i + 1]
                
                # Create training example for causal prediction
                source_features = self.aura.sbert.encode(source_event.get('summary', ''))
                target_features = self.aura.sbert.encode(target_event.get('summary', ''))
                
                causal_strength = target_event.get('causal_link', {}).get('effect_score', 0.5)
                
                training_examples.append({
                    'source_features': source_features,
                    'target_features': target_features,
                    'causal_strength': causal_strength,
                    'relationship_type': 'innovation_chain'
                })
        
        # Train on examples
        for example in training_examples[:50]:  # Limit for performance
            combined_features = np.concatenate([
                example['source_features'][:192],
                example['target_features'][:192]
            ])
            
            # Update causal reasoning neurons
            if hasattr(self.aura, '_conversational_cortex'):
                for neuron in self.aura._conversational_cortex.analytical_neurons[:3]:
                    try:
                        await neuron.update_nlms(combined_features, example['causal_strength'])
                    except:
                        pass
        
        print(f"üéØ Trained on {len(training_examples)} causal reasoning examples")
    
    def _generate_causal_context_features(self) -> np.ndarray:
        """Generate features representing current causal learning context"""
        
        features = np.zeros(384)
        
        # Basic statistics
        features[0] = min(1.0, self.causal_stats['total_events_processed'] / 1000)
        features[1] = min(1.0, self.causal_stats['causal_links_learned'] / 500)
        features[2] = min(1.0, self.causal_stats['butterfly_effects_analyzed'] / 100)
        
        # Pattern discovery progress
        features[3] = min(1.0, len(self.causal_patterns['innovation_chains']) / 20)
        features[4] = min(1.0, len(self.causal_patterns['cultural_influence_paths']) / 20)
        
        # Butterfly index distribution
        if self.causal_stats['butterfly_index_distribution']:
            features[5] = np.mean(self.causal_stats['butterfly_index_distribution'])
            features[6] = np.std(self.causal_stats['butterfly_index_distribution'])
        
        # Temporal coverage
        if self.temporal_clusters:
            features[7] = len(self.temporal_clusters) / 50.0  # Normalize
        
        return features
    
    async def _generate_causal_training_report(self):
        """Generate comprehensive causal intelligence training report"""
        
        print(f"""
üåä AURA CAUSAL HISTORY INTELLIGENCE TRAINING REPORT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üß† Causal Processing Statistics:
   ‚Ä¢ Total Events Processed: {self.causal_stats['total_events_processed']}
   ‚Ä¢ Causal Links Learned: {self.causal_stats['causal_links_learned']}
   ‚Ä¢ Butterfly Effects Analyzed: {self.causal_stats['butterfly_effects_analyzed']}
   ‚Ä¢ Counterfactual Scenarios: {self.causal_stats['counterfactual_scenarios_processed']}

üï∏Ô∏è Causal Network Analysis:
   ‚Ä¢ Causal Graph Nodes: {self.causal_graph.number_of_nodes()}
   ‚Ä¢ Causal Graph Edges: {self.causal_graph.number_of_edges()}
   ‚Ä¢ Similarity Network Edges: {self.similarity_graph.number_of_edges()}

üîç Pattern Discovery:
   ‚Ä¢ Innovation Chains: {len(self.causal_patterns['innovation_chains'])}
   ‚Ä¢ Cultural Influence Paths: {len(self.causal_patterns['cultural_influence_paths'])}
   ‚Ä¢ Temporal Clusters: {len(self.temporal_clusters)}

ü¶ã Butterfly Effect Analysis:
   ‚Ä¢ Total Scenarios: {len(self.butterfly_scenarios)}
   ‚Ä¢ Average Butterfly Index: {np.mean(self.causal_stats['butterfly_index_distribution']) if self.causal_stats['butterfly_index_distribution'] else 0:.3f}
   ‚Ä¢ High-Impact Events (>0.7): {sum(1 for x in self.causal_stats['butterfly_index_distribution'] if x > 0.7)}

üìä Cross-Type Causality Matrix:
{self._format_causality_matrix()}

üß† Enhanced Neural Capabilities:
   ‚Ä¢ Causal Reasoning: ‚úì
   ‚Ä¢ Temporal Pattern Recognition: ‚úì
   ‚Ä¢ Butterfly Effect Understanding: ‚úì
   ‚Ä¢ Counterfactual Analysis: ‚úì
   ‚Ä¢ Multi-hop Influence Tracking: ‚úì
   ‚Ä¢ Cross-domain Causal Links: ‚úì

üöÄ Advanced Intelligence Capabilities:
   ‚Ä¢ Historical Cause-Effect Analysis ‚úì
   ‚Ä¢ Counterfactual Scenario Generation ‚úì
   ‚Ä¢ Multi-hop Causal Chain Reasoning ‚úì
   ‚Ä¢ Temporal Causal Pattern Recognition ‚úì
   ‚Ä¢ Cross-domain Influence Analysis ‚úì
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        """)
    
    def _format_causality_matrix(self) -> str:
        """Format cross-type causality matrix for display"""
        
        matrix = self.causal_stats['event_type_causality_matrix']
        if not matrix:
            return "   ‚Ä¢ No cross-type patterns discovered yet"
        
        formatted = []
        for source_type, targets in list(matrix.items())[:5]:  # Top 5
            for target_type, strength in list(targets.items())[:3]:  # Top 3 targets
                formatted.append(f"   ‚Ä¢ {source_type} ‚Üí {target_type}: {strength:.2f}")
        
        return '\n'.join(formatted) if formatted else "   ‚Ä¢ No strong cross-type patterns found"

# Usage example for causal history training
async def train_aura_causal_intelligence():
    
    # Initialize Aura
    aura = IntegratedBioNeuralNetwork(domains=[], realms=[])
    
    # Initialize mapper for visualization  
    mapper = BioBrainNetworkMapper()
    
    # Create causal intelligence trainer
    causal_trainer = AuraCausalHistoryTrainer(aura, mapper)
    
    # Process causal history dataset
    await causal_trainer.process_causal_history_dataset("causal_events.jsonl")
    
    # Test Aura's enhanced causal intelligence
    print("\nüåä Testing Aura's Causal Intelligence:")
    
    causal_test_queries = [
        "What were the causal factors behind Berlioz's Symphonie Fantastique success?",
        "How did the John Bull locomotive test influence American railroad development?",
        "What would have happened if Berlioz's premiere had failed catastrophically?",
        "Trace the causal chain from early steam engines to modern transportation",
        "How do artistic innovations influence broader cultural movements?",
        "What butterfly effects can small historical events create?"
    ]
    
    for query in causal_test_queries:
        print(f"\nüîç User: {query}")
        response = await aura.process_with_cns_coordination(query)
        
        print(f"üåä Aura: {response['response_text'][:300]}...")
        print(f"üß† Causal Analysis: {response['specialists_used']}")
        print(f"‚ö° Neural State: {response['consciousness_level']} | Cognitive Load: {response['cognitive_load']:.2f}")

# Run causal intelligence training
if __name__ == "__main__":
    import trio
    trio.run(train_aura_causal_intelligence)
